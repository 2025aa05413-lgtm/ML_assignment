{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209a9b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic_Regression\n",
      "\n",
      "Training Decision_Tree\n",
      "\n",
      "Training KNN\n",
      "\n",
      "Training Naive_Bayes\n",
      "\n",
      "Training Random_Forest\n",
      "\n",
      "Training XGBoost\n",
      "                 Model  Accuracy       AUC  Precision    Recall        F1  \\\n",
      "0  Logistic_Regression  0.842391  0.925634   0.834862  0.892157  0.862559   \n",
      "1        Decision_Tree  0.815217  0.842181   0.814815  0.862745  0.838095   \n",
      "2                  KNN  0.847826  0.904890   0.842593  0.892157  0.866667   \n",
      "3          Naive_Bayes  0.847826  0.907221   0.855769  0.872549  0.864078   \n",
      "4        Random_Forest  0.858696  0.931014   0.858491  0.892157  0.875000   \n",
      "5              XGBoost  0.853261  0.913917   0.850467  0.892157  0.870813   \n",
      "\n",
      "        MCC  \n",
      "0  0.680376  \n",
      "1  0.624696  \n",
      "2  0.691317  \n",
      "3  0.691443  \n",
      "4  0.713336  \n",
      "5  0.702303  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score,\n",
    "    precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "\n",
    "# Replace '?' with NaN if present\n",
    "df.replace(\"?\", pd.NA, inplace=True)\n",
    "\n",
    "# Drop ID column\n",
    "df.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Target Engineering\n",
    "# -------------------------------\n",
    "df[\"num\"] = df[\"num\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "X = df.drop(\"num\", axis=1)\n",
    "y = df[\"num\"]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Column Groups\n",
    "# -------------------------------\n",
    "num_features = [\"age\", \"trestbps\", \"chol\", \"thalch\", \"oldpeak\"]\n",
    "cat_features = [\n",
    "    \"sex\", \"dataset\", \"cp\", \"fbs\",\n",
    "    \"restecg\", \"exang\", \"slope\",\n",
    "    \"ca\", \"thal\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Preprocessing Pipelines\n",
    "# -------------------------------\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline, num_features),\n",
    "        (\"cat\", categorical_pipeline, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Models\n",
    "# -------------------------------\n",
    "models = {\n",
    "    \"Logistic_Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision_Tree\": DecisionTreeClassifier(max_depth=6, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    \"Naive_Bayes\": GaussianNB(),\n",
    "    \"Random_Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Train-Test Split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Train, Evaluate, Save\n",
    "# -------------------------------\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}\")\n",
    "\n",
    "    if name == \"Naive_Bayes\":\n",
    "        # GaussianNB requires dense input\n",
    "        X_train_t = preprocessor.fit_transform(X_train)\n",
    "        X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "        model.fit(X_train_t, y_train)\n",
    "        y_pred = model.predict(X_test_t)\n",
    "        y_proba = model.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "        joblib.dump((preprocessor, model), f\"model/{name}.pkl\")\n",
    "\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        joblib.dump(pipeline, f\"model/{name}.pkl\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Save Metrics\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model/model_metrics.csv\", index=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e711bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
